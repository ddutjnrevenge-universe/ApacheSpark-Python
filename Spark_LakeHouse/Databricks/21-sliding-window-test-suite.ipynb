{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67ce30de-1f23-43f1-93c8-9ac11a42d83f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./20-sliding-window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b25c78-968b-4051-bc86-f234a74d08d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SensorSummaryTestSuite():\n",
    "    def __init__(self):\n",
    "        self.base_data_dir = \"/FileStore/data_spark_streaming\"\n",
    "\n",
    "    def cleanTests(self):\n",
    "        print(f\"Starting Cleanup...\", end='')\n",
    "        spark.sql(\"drop table if exists kafka_bz\")\n",
    "        spark.sql(\"drop table if exists sensor_summary\")\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/kafka_bz\", True)\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/sensor_summary\", True)\n",
    "        spark.sql(f\"CREATE TABLE kafka_bz(key STRING, value STRING)\")\n",
    "\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/checkpoint/sensor_summary\", True)\n",
    "        print(\"Done\")\n",
    "\n",
    "    def waitForMicroBatch(self, sleep=60):\n",
    "        import time\n",
    "        print(f\"\\tWaiting for {sleep} seconds...\", end='')\n",
    "        time.sleep(sleep)\n",
    "        print(\"Done.\")    \n",
    "\n",
    "    def assertSensorSummary(self, id, start, end, expected_max):\n",
    "        print(f\"\\tStarting Sensor Summary validation...\", end='')\n",
    "        actual_result = spark.table(\"sensor_summary\").collect()\n",
    "        expected_result = (spark.read.format(\"csv\")\n",
    "                                .option(\"header\", \"true\")\n",
    "                                .load(f\"{self.base_data_dir}/data/results/sensor/sliding_window_result.csv\")\n",
    "                                .collect()\n",
    "                            )\n",
    "        assert expected_result == actual_result, f\"Test failed! actual max is {actual_result}\"\n",
    "        print(\"Done\")\n",
    "\n",
    "    def runTests(self):\n",
    "        self.cleanTests()\n",
    "\n",
    "        stream = SlidingAggregate()\n",
    "        sQuery = stream.process()       \n",
    "\n",
    "        print(\"\\nTesting all events...\") \n",
    "        spark.sql(\"\"\"INSERT INTO kafka_bz VALUES\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 09:54:00\",\"Reading\": 36.2}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 09:59:00\",\"Reading\": 36.5}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:04:00\",\"Reading\": 36.8}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:09:00\",\"Reading\": 36.2}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:14:00\",\"Reading\": 36.5}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:19:00\",\"Reading\": 36.3}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:24:00\",\"Reading\": 37.7}'),\n",
    "                  ('SET41', '{\"CreatedTime\": \"2019-02-05 10:29:00\",\"Reading\": 37.2}')\n",
    "            \"\"\")\n",
    "        self.waitForMicroBatch()\n",
    "        print(\"Validation passed.\\n\")        \n",
    "\n",
    "        sQuery.stop()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd8dbaa-62b0-4422-97fe-f345bf65a2e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cleanup...Done\n\nStarting Silver Stream...\nTesting all events...\n\tWaiting for 60 seconds...Done.\nValidation passed.\n\n"
     ]
    }
   ],
   "source": [
    "ts = SensorSummaryTestSuite()\n",
    "ts.runTests()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "21-sliding-window-test-suite",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
