{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65c97d31-edc1-4a08-a0df-8dbee26f5251",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./14-streaming-incremental-aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6107fdb8-de64-4acb-8250-b0cb82a7968b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AggregationTestSuite():\n",
    "    def __init__(self):\n",
    "        self.base_data_dir = \"/FileStore/data_spark_streaming\"\n",
    "\n",
    "    def cleanTests(self):\n",
    "        print(f\"Starting Cleanup...\", end='')\n",
    "        spark.sql(\"drop table if exists invoices_bz\")\n",
    "        spark.sql(\"drop table if exists customer_rewards\")\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/invoices_bz\", True)\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/customer_rewards\", True)\n",
    "\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/checkpoint/invoices_bz\", True)\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/checkpoint/customer_rewards\", True)\n",
    "\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/data/aggregate/invoices\", True)\n",
    "        dbutils.fs.mkdirs(f\"{self.base_data_dir}/data/aggregate/invoices\")\n",
    "        print(\"Done\")\n",
    "\n",
    "    def ingestData(self, itr):\n",
    "        print(f\"\\tStarting Ingestion...\", end='')\n",
    "        dbutils.fs.cp(f\"{self.base_data_dir}/data/invoices_{itr}.json\", f\"{self.base_data_dir}/data/aggregate/invoices/\")\n",
    "        print(\"Done\")\n",
    "\n",
    "    def assertBronze(self, expected_count):\n",
    "        print(f\"\\tStarting Bronze validation...\", end='')\n",
    "        actual_count = spark.sql(\"select count(*) from invoices_bz\").collect()[0][0]\n",
    "        assert expected_count == actual_count, f\"Test failed! actual count is {actual_count}\"\n",
    "        print(\"Done\")\n",
    "\n",
    "    def assertGold(self, expected_value):\n",
    "        print(f\"\\tStarting Gold validation...\", end='')\n",
    "        actual_value = spark.sql(\"select TotalAmount from customer_rewards where CustomerCardNo = '2262471989'\").collect()[0][0]\n",
    "        assert expected_value == actual_value, f\"Test failed! actual value is {actual_value}\"\n",
    "        print(\"Done\")\n",
    "\n",
    "    def waitForMicroBatch(self, sleep=60):\n",
    "        import time\n",
    "        print(f\"\\tWaiting for {sleep} seconds...\", end='')\n",
    "        time.sleep(sleep)\n",
    "        print(\"Done.\")    \n",
    "\n",
    "    def runTests(self):\n",
    "        self.cleanTests()\n",
    "        # Ensure the customer_rewards table is created\n",
    "        spark.sql(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS customer_rewards (\n",
    "            CustomerCardNo STRING,\n",
    "            TotalAmount DOUBLE,\n",
    "            TotalPoints DOUBLE\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        spark.conf.set(\"spark.sql.streaming.stateStore.rpoviderClass\",\n",
    "                       \"org.apache.spark.sql.execution.streaming.state.RocksDBStateStoreProvider\")\n",
    "        bzStream = Bronze()\n",
    "        bzQuery = bzStream.process()\n",
    "        gdStream = Gold()\n",
    "        gdQuery = gdStream.process()       \n",
    "\n",
    "        print(\"\\nTesting first iteration of invoice stream...\") \n",
    "        self.ingestData(1)\n",
    "        self.waitForMicroBatch()        \n",
    "        self.assertBronze(501)\n",
    "        self.assertGold(36859)\n",
    "        print(\"Validation passed.\\n\")\n",
    "\n",
    "        print(\"\\nTesting second iteration of invoice stream...\") \n",
    "        self.ingestData(2)\n",
    "        self.waitForMicroBatch()        \n",
    "        self.assertBronze(501+500)\n",
    "        self.assertGold(36859+20740)\n",
    "        print(\"Validation passed.\\n\")\n",
    "\n",
    "        print(\"\\nTesting second iteration of invoice stream...\") \n",
    "        self.ingestData(3)\n",
    "        self.waitForMicroBatch()        \n",
    "        self.assertBronze(501+500+590)\n",
    "        self.assertGold(36859+20740+31959)\n",
    "        print(\"Validation passed.\\n\")\n",
    "\n",
    "        bzQuery.stop()\n",
    "        gdQuery.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e40c0b71-8d0e-4c49-bc6a-059ff6721e95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cleanup...Done\n\nStarting Bronze Stream...Done\n\nStarting Silver Stream...\nTesting first iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 60 seconds...Done.\n\tStarting Bronze validation...Done\n\tStarting Gold validation...Done\nValidation passed.\n\n\nTesting second iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 60 seconds...Done.\n\tStarting Bronze validation...Done\n\tStarting Gold validation...Done\nValidation passed.\n\n\nTesting second iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 60 seconds...Done.\n\tStarting Bronze validation...Done\n\tStarting Gold validation...Done\nValidation passed.\n\n"
     ]
    }
   ],
   "source": [
    "aTS = AggregationTestSuite()\n",
    "aTS.runTests()\t"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "15-streaming-incremental-aggregates-test-suite",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
