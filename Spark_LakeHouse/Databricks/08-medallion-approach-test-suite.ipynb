{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a46ddcd-ed2e-4f43-b715-2bc5741a059f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./07-medallion-approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce448175-8232-4880-82ce-01b308bc5bdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.rm(f\"/FileStore/data_spark_streaming/data/medallion\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f1cd685-c3d3-4407-b56d-20332651d493",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class medallionApproachTestSuite():\n",
    "    def __init__(self):\n",
    "        self.base_data_dir = \"/FileStore/data_spark_streaming\"\n",
    "\n",
    "    def cleanTests(self):\n",
    "        print(\"Starting Cleanup...\", end=\"\")\n",
    "        spark.sql(\"drop table if exists invoices_bz\")\n",
    "        spark.sql(\"drop table if exists invoice_line_items\")\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/invoices_bz\", True)\n",
    "        dbutils.fs.rm(\"/user/hive/warehouse/invoice_line_items\", True)\n",
    "        \n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/checkpoint/invoices_bz\", True)\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/checkpoint/invoice_line_items\", True)\n",
    "        \n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/data/medallion/invoices_archive\", True)\n",
    "        dbutils.fs.rm(f\"{self.base_data_dir}/data/medallion/invoices\", True)\n",
    "        dbutils.fs.mkdirs(f\"{self.base_data_dir}/data/medallion/invoices\")\n",
    "        \n",
    "        print(\"Done\")\n",
    "\n",
    "    def ingestData(self, itr):\n",
    "        print(f\"\\tStarting Ingestion...\", end='')\n",
    "        dbutils.fs.cp(f\"{self.base_data_dir}/data/invoices_{itr}.json\", f\"{self.base_data_dir}/data/medallion/invoices/\")\n",
    "        print(\"Done\")\n",
    "\n",
    "    def assertResult(self, expected_count):\n",
    "        print(f\"\\tStarting validation...\", end='')\n",
    "        actual_count = spark.sql(\"select count(*) from invoice_line_items\").collect()[0][0]\n",
    "        assert expected_count == actual_count, f\"Test failed! actual count is {actual_count}\"\n",
    "        print(\"Done\")\n",
    "\n",
    "    def waitForMicroBatch(self, sleep=30):\n",
    "        import time\n",
    "        print(f\"\\tWaiting for {sleep} seconds...\", end='')\n",
    "        time.sleep(sleep)\n",
    "        print(\"Done.\")\n",
    "\n",
    "    def runTests(self):\n",
    "        self.cleanTests()\n",
    "        \n",
    "        bzStream = Bronze()\n",
    "        bzQuery = bzStream.process()\n",
    "        \n",
    "        slStream = Silver()\n",
    "        slQuery = slStream.process()\n",
    "\n",
    "        print(\"Testing first iteration of invoice stream...\") \n",
    "        self.ingestData(1)\n",
    "        self.waitForMicroBatch()        \n",
    "        self.assertResult(1253)\n",
    "        print(\"Validation passed.\\n\")\n",
    "\n",
    "        print(\"Testing second iteration of invoice stream...\") \n",
    "        self.ingestData(2)\n",
    "        self.waitForMicroBatch()\n",
    "        self.assertResult(2510)\n",
    "        print(\"Validation passed.\\n\") \n",
    "\n",
    "        print(\"Testing third iteration of invoice stream...\") \n",
    "        self.ingestData(3)\n",
    "        self.waitForMicroBatch()\n",
    "        self.assertResult(3994)\n",
    "        print(\"Validation passed.\\n\")\n",
    "\n",
    "        bzQuery.stop()\n",
    "        slQuery.stop()\n",
    "\n",
    "        print(\"Validating Archive...\", end=\"\")\n",
    "        archived_expected = [\"invoices_1.json\", \"invoices_2.json\"]\n",
    "        archived_files = dbutils.fs.ls(f\"{self.base_data_dir}/data/medallion/invoices_archive/{self.base_data_dir}/data/medallion/invoices\")\n",
    "        archived_file_names = [f.name for f in archived_files]\n",
    "        for file_name in archived_file_names:\n",
    "            assert file_name in archived_expected, f\"Archive Validation failed for {file_name}\"\n",
    "        print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac25ff1b-8e4c-4f27-b0bd-07aab0e603f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cleanup...Done\n\nStarting Bronze Stream...Done\n\nStarting Silver Stream...Done.\n\nTesting first iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 30 seconds...Done.\n\tStarting validation...Done\nValidation passed.\n\nTesting second iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 30 seconds...Done.\n\tStarting validation...Done\nValidation passed.\n\nTesting third iteration of invoice stream...\n\tStarting Ingestion...Done\n\tWaiting for 30 seconds...Done.\n\tStarting validation...Done\nValidation passed.\n\nValidating Archive...Done\n"
     ]
    }
   ],
   "source": [
    "maTS = medallionApproachTestSuite()\n",
    "maTS.runTests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5342d8e9-dc90-4b6e-9a6b-2a8f9443a0dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08-medallion-approach-test-suite",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
