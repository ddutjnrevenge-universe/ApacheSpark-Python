{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d42468b6-bd7a-4144-99b6-4a67b11885ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TradeSummary():\n",
    "    def __init__(self):\n",
    "        self.base_data_dir = \"/FileStore/data_spark_streaming\"\n",
    "    \n",
    "    def getSchema(self):\n",
    "        from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "        return StructType([\n",
    "            StructField(\"CreatedTime\", StringType()),\n",
    "            StructField(\"Type\", StringType()),\n",
    "            StructField(\"Amount\", DoubleType()),\n",
    "            StructField(\"BrokerCode\", StringType())\n",
    "        ])\n",
    "\n",
    "    def readBronze(self):\n",
    "        return spark.readStream.table(\"kafka_bz\")\n",
    "    \n",
    "    def getTrade(self, kafka_df):\n",
    "        from pyspark.sql.functions import from_json, expr\n",
    "        return ( kafka_df.select(from_json(kafka_df.value, self.getSchema()).alias(\"value\"))\n",
    "                .select(\"value.*\")\n",
    "                .withColumn(\"CreatedTime\", expr(\"to_timestamp(CreatedTime, 'yyyy-MM-dd HH:mm:ss')\"))\n",
    "                .withColumn(\"Buy\", expr(\"case when Type == 'BUY' then Amount else 0 end\"))\n",
    "                .withColumn(\"Sell\", expr(\"case when Type == 'SELL' then Amount else 0 end\"))\n",
    "        )\n",
    "    \n",
    "    def getAggregate(self, trades_df):\n",
    "        from pyspark.sql.functions import window, sum\n",
    "        return (trades_df.withWatermark(\"CreatedTime\", \"30 minutes\")\n",
    "                        .groupBy(window(trades_df.CreatedTime, \"15 minutes\"))\n",
    "                        .agg(sum(\"Buy\").alias(\"TotalBuy\"),\n",
    "                             sum(\"Sell\").alias(\"TotalSell\"))\n",
    "                        .select(\"window.start\", \"window.end\", \"TotalBuy\", \"TotalSell\")\n",
    "                )\n",
    "\n",
    "    def saveResults(self, results_df):\n",
    "        print(f\"\\nStarting Silver Stream...\", end='')\n",
    "        return (results_df.writeStream\n",
    "                    .queryName(\"trade-summary\")\n",
    "                    .option(\"checkpointLocation\", f\"{self.base_data_dir}/checkpoint/trade_summary\")\n",
    "                    .outputMode(\"complete\")\n",
    "                    .toTable(\"trade_summary\")\n",
    "                )\n",
    "        print(\"Done\")\n",
    "\n",
    "    def process(self):\n",
    "        kafka_df = self.readBronze()\n",
    "        trades_df = self.getTrade(kafka_df)\n",
    "        results_df = self.getAggregate(trades_df)        \n",
    "        sQuery = self.saveResults(results_df)\n",
    "        return sQuery\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "18-tumbling-time-window",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
